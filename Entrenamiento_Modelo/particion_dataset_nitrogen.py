# -*- coding: utf-8 -*-
"""Particion_dataset_Nitrogen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YXrS1NQGDTwx4DY2KQ5Y_Xdy_OCIv_Du
"""

import numpy as np
import pandas as pd
import random
from google.colab import files
from google.colab import drive
import os

# Set up location
drive.mount('/content/drive')

base_path = "/content/sample_data"

# --- Cargar datos desde sample_data ---
data = pd.read_csv(os.path.join(base_path, "dataset.csv"))

data.head()

data.info()

# Dividir el 80% Train / 20% Test
n = len(data)
train_size = int(n * 0.8)

# Divide el dataset completo en conjunto de entrenamiento
# Selecciona las primeras 'train_size' filas y reinicia los índices para evitar desorden
df_train_full = data.iloc[:train_size].reset_index(drop=True)

# Divide el dataset completo en conjunto de prueba
# Selecciona las filas desde 'train_size' hasta el final y reinicia los índices
df_test = data.iloc[train_size:].reset_index(drop=True)

# Dividir el Train Full,  80% Train Final / 20% Validación
n_train_full = len(df_train_full)
train_final_size = int(n_train_full * 0.8)

df_train = df_train_full.iloc[:train_final_size].reset_index(drop=True)
df_val = df_train_full.iloc[train_final_size:].reset_index(drop=True)

# Mostrar tamaños
print(f"Training set    : {len(df_train)}")
print(f"Validation set  : {len(df_val)}")
print(f"Test set        : {len(df_test)}")

# Guardar como lista de DataFrames en un solo archivo .pkl
ruta_salida = "/content/drive/MyDrive/Tesis/datasets_particiones"
os.makedirs(ruta_salida, exist_ok=True)
pd.to_pickle([df_train, df_test, df_val], os.path.join(ruta_salida, "dataset_nitrogen.pkl"))