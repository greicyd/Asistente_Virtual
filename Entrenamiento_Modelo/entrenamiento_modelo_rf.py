# -*- coding: utf-8 -*-
"""Entrenamiento_modelo_RF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_wZTA71cYQA-qdgc2nrwkQ6wcYEWTjk9
"""

# Importa la librería NumPy, útil para operaciones numéricas y manejo de arrays
import numpy as np

# Importa la librería Pandas, útil para manipulación y análisis de datos en estructuras DataFrame
import pandas as pd

# Importa timedelta desde datetime, permite trabajar con diferencias de tiempo y fechas
from datetime import timedelta

# Importa el módulo random, usado para generar números aleatorios
import random

# Importa RandomForestClassifier de scikit-learn, un algoritmo de machine learning basado en árboles de decisión
from sklearn.ensemble import RandomForestClassifier

# Importa el módulo os, útil para interactuar con el sistema operativo (manejo de archivos, rutas, etc.)
import os

# Importa drive desde google.colab, permite montar Google Drive en Colab para acceder a archivos
from google.colab import drive

# Importa seaborn, una librería para visualización de datos basada en matplotlib
import seaborn as sns

# Importa matplotlib.pyplot, utilizado para crear gráficos y visualizaciones
import matplotlib.pyplot as plt

# Importa pandas nuevamente (ya se había importado antes), redundante pero no causa error
import pandas as pd

# Importa RandomForestClassifier nuevamente (ya se había importado antes), también redundante
from sklearn.ensemble import RandomForestClassifier

# Importa métricas de scikit-learn para evaluar modelos: exactitud, precisión, recall, F1, ROC AUC y matriz de confusión
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# Importa learning_curve de scikit-learn, útil para generar curvas de aprendizaje y evaluar el desempeño del modelo según la cantidad de datos
from sklearn.model_selection import learning_curve

# Importa pickle, usado para guardar y cargar objetos de Python (como modelos entrenados)
import pickle

# Localización de Google Drive
drive.mount('/content/drive')

# Definir parámetros
PW = "0.5"  # Prediction Window
RW_minutes = 10  # Reading Window en minutos
folder = f"PW_{PW}h"

# Cargar los datasets
file_path = "/content/drive/MyDrive/Tesis/datasets_particiones/dataset_nitrogen.pkl"
if os.path.exists(file_path):
    df_train, df_test, df_val = pd.read_pickle(file_path)
else:
    print(f"Error: File not found at {file_path}")
    print("Please check the file path and ensure the file exists in your Google Drive.")

# Mostrar tamaños
print(f"Training set    : {len(df_train)}")
print(f"Validation set  : {len(df_val)}")
print(f"Test set        : {len(df_test)}")

# Convierte la columna "timestamp" de cada DataFrame a tipo datetime para poder trabajar con fechas
df_train["timestamp"] = pd.to_datetime(df_train["timestamp"])
df_val["timestamp"] = pd.to_datetime(df_val["timestamp"])
df_test["timestamp"] = pd.to_datetime(df_test["timestamp"])

# Establece la columna "timestamp" como índice del DataFrame para facilitar operaciones basadas en tiempo
df_train.set_index("timestamp", inplace=True)
df_val.set_index("timestamp", inplace=True)
df_test.set_index("timestamp", inplace=True)

# Función para dividir un DataFrame en ventanas temporales solapadas
def split_into_windows(df, window_size, step):
    # Guarda el primer y último timestamp del DataFrame
    start_time = df.index[0]
    end_time = df.index[-1]

    # Define el final de la primera ventana sumando el tamaño de ventana al inicio
    window_end_time = start_time + window_size

    # Mientras la ventana no sobrepase el final del DataFrame
    while window_end_time <= end_time:
        # Extrae los datos dentro de la ventana actual
        window = df.loc[start_time:df.index.asof(window_end_time)]

        # Devuelve la ventana actual (yield permite iterar sin crear todas las ventanas a la vez)
        yield window

        # Avanza el inicio y el fin de la ventana según el paso definido
        start_time += step
        window_end_time += step

# Define el tamaño de la ventana como un timedelta de RW_minutes (ventana en minutos)
window_size = timedelta(minutes=RW_minutes)
# Define el paso entre ventanas como la diferencia de tiempo entre los dos primeros timestamps del DataFrame
# Esto asume que los datos están ordenados temporalmente y tienen un intervalo constante
step = df_train.index[1] - df_train.index[0]

# Función para crear un dataset basado en ventanas temporales
# Cada elemento del dataset es una tupla: (features de la ventana, label de la última fila de la ventana)
def create_windowed_dataset(df, window_size, step, target_col):
    result = []  # Lista para almacenar las tuplas (features, label) de cada ventana

    # Itera sobre cada ventana generada por split_into_windows
    for window in split_into_windows(df, window_size, step):
        # Selecciona todas las columnas excepto la última como features
        features = window.iloc[:, :-1]

        # Toma la columna target de la última fila de la ventana como label
        label = window.iloc[-1][target_col]

        # Añade la tupla (features, label) al resultado
        result.append((features, label))

    # Devuelve la lista completa de ventanas con sus etiquetas
    return result

# Crea el dataset de entrenamiento a partir de df_train, segmentado en ventanas de tamaño window_size y paso step
# Cada elemento es una tupla (features de la ventana, label de la última fila)
train_result = create_windowed_dataset(df_train, window_size, step, folder)
# Crea el dataset de test a partir de df_test, usando las mismas ventanas y paso que en entrenamiento
test_result = create_windowed_dataset(df_test, window_size, step, folder)
# Crea el dataset de validación a partir de df_val, nuevamente con las mismas ventanas y paso
val_result = create_windowed_dataset(df_val, window_size, step, folder)

# Función para balancear un dataset de ventanas para que ambas clases tengan la misma cantidad de muestras
def balance_windows(result, seed=42):
    # Fija la semilla para reproducibilidad de la selección aleatoria
    random.seed(seed)

    # Separa las ventanas según la etiqueta: clase 0 y clase 1
    class_0_windows = [w for w, label in result if label == 0]
    class_1_windows = [w for w, label in result if label == 1]

    # Determina la cantidad mínima de ventanas entre las dos clases
    min_count = min(len(class_0_windows), len(class_1_windows))

    # Selecciona aleatoriamente min_count ventanas de cada clase
    selected_class_0 = random.sample(class_0_windows, min_count)
    selected_class_1 = random.sample(class_1_windows, min_count)

    # Combina las ventanas seleccionadas y les asigna sus etiquetas correspondientes
    balanced = [(w, 0) for w in selected_class_0] + [(w, 1) for w in selected_class_1]

    # Mezcla aleatoriamente las ventanas para evitar orden sesgado
    random.shuffle(balanced)

    # Devuelve la lista de ventanas balanceadas
    return balanced

# Aplica solo sobre train_result para balancear
balanced_train_result = balance_windows(train_result)

# Función para separar features y labels de una lista de ventanas
def extract_features_labels(windows_list):
    # Extrae los valores de las ventanas como features (solo los datos, sin la etiqueta)
    features = [window.values for window, _ in windows_list]

    # Extrae las etiquetas correspondientes a cada ventana
    labels = [label for _, label in windows_list]

    # Devuelve las features y labels como arrays de NumPy para que sean compatibles con scikit-learn
    return np.array(features), np.array(labels)

# Función para "aplanar" las features de cada ventana en un vector 1D
def flatten_features(features):
    # Guarda la forma original del array (num_ventanas, num_filas_por_ventana, num_columnas)
    orig_shape = features.shape

    # Cambia la forma del array a 2D: (num_ventanas, num_filas_por_ventana * num_columnas)
    # Esto convierte cada ventana en un vector lineal, útil para modelos que esperan vectores 1D por muestra
    return features.reshape((orig_shape[0], orig_shape[1] * orig_shape[2]))

# Extraer features y labels
train_features, train_labels = extract_features_labels(balanced_train_result)
val_features, val_labels = extract_features_labels(val_result)
test_features, test_labels = extract_features_labels(test_result)

# Función para calcular pesos de las clases según su frecuencia en el dataset
# Esto es útil para modelos que soportan sample_weights o class_weight, para balancear clases desiguales
def calculate_sample_weights(result):
    # Cuenta cuántas ventanas corresponden a la clase 0
    class_0_count = sum(1 for _, label in result if label == 0)

    # Cuenta cuántas ventanas corresponden a la clase 1
    class_1_count = sum(1 for _, label in result if label == 1)

    # Calcula el total de ventanas
    total = class_0_count + class_1_count

    # Calcula el peso de cada clase como inversamente proporcional a su frecuencia
    weight_class_0 = total / class_0_count
    weight_class_1 = total / class_1_count

    # Devuelve los pesos de las clases
    return weight_class_0, weight_class_1

# Calcula los pesos de las clases en el dataset de validación (val_result)
# weight_class_0 y weight_class_1 serán usados para balancear la influencia de cada clase en el modelo
weight_class_0, weight_class_1 = calculate_sample_weights(val_result)

# Crea una lista de pesos para cada muestra de validación según su etiqueta
# Cada ventana recibe el peso correspondiente a su clase (weight_class_0 o weight_class_1)
sample_weights = [weight_class_0 if label == 0 else weight_class_1 for label in val_labels]

# Inicializa las variables para almacenar el mejor F1 score y el mejor modelo encontrado durante la búsqueda
best_f1_score, best_model = None, None

# Lista para guardar los resultados de todas las combinaciones de hiperparámetros
resultados = []

# Iteramos sobre combinaciones de hiperparámetros: max_features y n_estimators
for mf in [0.33, None, "sqrt", "log2"]:
    for n_estimators in [100, 150, 200]:
        # Creamos un modelo RandomForest con la combinación actual de hiperparámetros
        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_features=mf,
        )

        # Entrenamos el modelo con los datos de entrenamiento
        model.fit(train_features, train_labels)

        # Hacemos predicciones sobre los datos de validación
        y_pred = model.predict(val_features)

        # Probabilidades de predicción para la clase positiva (solo si hay dos clases)
        y_proba = model.predict_proba(val_features)[:,1] if len(set(val_labels)) == 2 else None

        # Calculamos métricas de evaluación
        accuracy_val = accuracy_score(val_labels, y_pred)
        precision_val = precision_score(val_labels, y_pred, average="macro", sample_weight=sample_weights)
        recall_val = recall_score(val_labels, y_pred, average="macro")
        f1_val = f1_score(val_labels, y_pred, average="macro", sample_weight=sample_weights)
        roc_auc_val = roc_auc_score(val_labels, y_proba, sample_weight=sample_weights) if y_proba is not None else None

        # Guardamos el mejor modelo según el F1 score
        if best_f1_score is None:
            best_f1_score = f1_val
            best_model = model
        elif f1_val > best_f1_score:
            best_f1_score = f1_val
            best_model = model

        # Guardamos los resultados de esta combinación en la lista
        resultados.append({
            "n_estimators": n_estimators,
            "max_features": mf,
            "Accuracy": accuracy_val,
            "Precision": precision_val,
            "Recall": recall_val,
            "F1": f1_val,
            "ROC_AUC": roc_auc_val
        })

# Convertimos la lista de resultados a un DataFrame para facilitar su análisis
df_resultados = pd.DataFrame(resultados)

# Mostramos la tabla completa de resultados
print(df_resultados)

# Identificamos la fila correspondiente al mejor modelo según F1
best_model_row = df_resultados.loc[df_resultados["F1"].idxmax()]
print("\nMejor modelo:\n", best_model_row)

# Realiza predicciones sobre el conjunto de test usando el mejor modelo encontrado
y_test_pred = best_model.predict(test_features)

# Calcula métricas de evaluación para el conjunto de test
accuracy_test = accuracy_score(test_labels, y_test_pred)  # Exactitud
precision_test = precision_score(test_labels, y_test_pred)  # Precisión
recall_test = recall_score(test_labels, y_test_pred)  # Recall
f1_score_test = f1_score(test_labels, y_test_pred, average='macro')  # F1 score ponderado
conf_matrix_test = confusion_matrix(test_labels, y_test_pred)  # Matriz de confusión

# Imprime los resultados
print("Testing Set Metrics:")
print("Accuracy:", accuracy_test)
print("Precision:", precision_test)
print("Recall:", recall_test)
print("F1 Score:", f1_score_test)

# Crea una figura de tamaño 6x4 pulgadas
plt.figure(figsize=(6,4))

# Dibuja un mapa de calor de la matriz de confusión usando Seaborn
# annot=True muestra los valores dentro de cada celda
# fmt='d' formatea los números como enteros
# cmap='Blues' aplica una escala de colores azul
sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues')

# Etiqueta del eje X
plt.xlabel('Predicted Label')

# Etiqueta del eje Y
plt.ylabel('True Label')

# Título del gráfico
plt.title('Confusion Matrix - Test Set')

# Muestra el gráfico
plt.show()